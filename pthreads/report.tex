\documentclass[a4paper]{article}

\usepackage{array}
\usepackage{fullpage}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage[all]{hypcap}
\usepackage{listings}
\usepackage{color}
\usepackage{graphicx}
\usepackage{multicol}

\definecolor{light-gray}{gray}{0.95}
\definecolor{dark-green}{rgb}{0, 0.5, 0}
\definecolor{dark-gray}{gray}{0.4}
\definecolor{Gray}{gray}{0.95}

\lstset{ %
	language = C,                   % choose the language of the code
	basicstyle = \small\ttfamily,   % the size and fonts that are used
	frame = single,                 % adds a frame around the code
	tabsize = 3,                    % sets default tabsize
	breaklines = true,              % sets automatic line breaking
	numbers = left,                 % where to put the line-numbers
	numberstyle = \footnotesize,    % the style of the line-numbers
	backgroundcolor = \color{Gray}, % the background color of the listing
	showstringspaces=false,
	keywordstyle=\color{blue},
}

\newcolumntype{V}{>{\centering\arraybackslash} m{.75\linewidth} }

\title{Assignment 4: pthreads}
\author{Jacco Spoelder (s1348493) \and Xeryus Stokkel (s2332795)}

\begin{document}

\maketitle

\section{Exercise 1}

\section{Exercise 2}
We split the program into stages according to the diagram in the assignment. The first stage reads the images, the second stage thresholds the image, the third stage splits the image into separate characters and creates a string of images out if it, the fourth stage converts the string of images to a regular string through correlation and and the final stage outputs the results of the previous steps.

We use a shared buffer between stages to share the data from one stage to the next stage. Each intermediate step has its own buffer. We devised a way to notify the next stage that the buffer has been filled so it can work on it. We did this in such a way that when for example, there is one thread working on stage 1 and 4 on stage 2 that only one of the threads in stage 2 would work on the data in the buffer so that we don't accidentally duplicate work to be done. This signalling is based on semaphores, a thread signals the next stage that new data is in the buffer is simply done by increasing the semaphore, the receiving end has to make sure that another thread didn't read the data beforehand. The code to do this can be found in \autoref{code:ex2-1}.

\lstinputlisting[label={code:ex2-1}, caption={Code a stage uses to receive the signal that the previous stage has filled the buffer.}, firstline=606, lastline=613]{ocr-ex2.c}

Next the data is copied into a local buffer and the shared buffer is released so that the input stage can fill it again. After this the stage does the core of its work. Finally it waits for the next stage to signal that it has emptied the buffer so that it can safely fill it again without overwriting data. This is shown in \autoref{code:ex2-2} (copying to the shared buffer is not included), the variable \texttt{thresholdAvailable} is set according to whether there is data in the shared buffer.

\lstinputlisting[label={code:ex2-2}, caption={Code a stage uses to signal the next stage that new data is available in the buffer.}, firstline=627, lastline=633]{ocr-ex2.c}

We also wrote a image string datatype. This datatype is basically a string but it allows storing images besides characters. This way we can preserve the order or characters and their relationship to each other. It also allows storing white space which have no associated images. All in all this allows us to keep the structure of the page while not writing to stdout directly like in the start code. The code is in \autoref{code:stringbuffer.h} and \autoref{code:stringbuffer.c} in \autoref{sec:aux}.

In \autoref{tbl:ex2} we show the run time, CPU utilization and speed-up for different number of threads per stage. Stage 1 and 5 always have one thread because they only do I/O and we don't want doing simultaneous I/O influencing our results. From \autoref{tbl:ex2} we can see that only increasing the number of threads used for correlation influences the speed up. From this we can conclude that the main bottleneck of the program is the correlation step, all other steps have to wait for this step to complete before they can do anything else.

It should also be noted that having more threshold and segmentation threads negatively influences the speed-up. This might just be down to variations in run-time but it might also be indicative that the threads of one stage spend more time waiting on each other to fill the buffer and slightly slowing the program down that way.

From the CPU utilization we can see that most threads spend a lot of time waiting for each other with only one thread, only $\approx 1.6$ core is used. When we increase the number of correlation threads we see that the CPU utilization doubles straight away. This means that not only correlation goes faster but that the other stages spend less time waiting around on the correlation stage.

Doing the work in a pipeline fashion does have some benefit, we can see that with even 1 thread for every stage gives a small speed-up. This means that it can be worthwhile to split a program into different pipeline stages, but it took us a bit of effort to do this in a way that doesn't lead to a program that hangs very often.

\begin{table}[t]
	\centering
	\label{tbl:ex2}
	\caption{Run times for different number of threads working on certain stages.}
	\begin{tabular}{r|r|r|r|r|r}
		\multicolumn{3}{c|}{Number of threads per stage} & \multicolumn{2}{c}{}\\
		Threshold & Segmentation & Correlation & Time & CPU & Speed-up \\ \hline
		\multicolumn{3}{c|}{Sequential} & 72.13 & 100\% & \\ \cline{1-3}
		1 & 1 & 1 & 60.92 & 165\% & 1.18 \\
		1 & 1 & 2 & 31.24 & 322\% & 2.31 \\
		1 & 1 & 3 & 22.59 & 449\% & 3.19 \\
		1 & 2 & 1 & 60.50 & 163\% & 1.19 \\
		1 & 2 & 2 & 31.55 & 322\% & 2.29 \\
		1 & 2 & 3 & 23.48 & 437\% & 3.07 \\
		1 & 3 & 1 & 63.04 & 160\% & 1.14 \\
		1 & 3 & 2 & 31.90 & 319\% & 2.26 \\
		1 & 3 & 3 & 22.16 & 467\% & 3.25 \\
		2 & 1 & 1 & 60.11 & 164\% & 1.20 \\
		2 & 1 & 2 & 30.59 & 326\% & 2.36 \\
		2 & 1 & 3 & 22.27 & 456\% & 3.24 \\
		2 & 2 & 1 & 61.38 & 161\% & 1.18 \\
		2 & 2 & 2 & 26.62 & 342\% & 2.71 \\
		2 & 2 & 3 & 22.12 & 496\% & 3.26 \\
		3 & 3 & 1 & 61.69 & 162\% & 1.17 \\
		3 & 3 & 2 & 27.87 & 334\% & 2.59 \\
		3 & 3 & 3 & 22.22 & 464\% & 3.25 \\
	\end{tabular}
\end{table}

\section{Exercise 3}

To split the program into a master/worker model we implemented a queue that holds an image file and the filename that belongs to that image. The main thread fills the queue as long as there are places left in it. Each worker reads the image and filename from the queue and execute the entire processing pipeline. We also store the filename in the queue so that the output is the same as in the vanilla program where the filename precedes the contents of the file.

Run times and speed-up for this model are shown in \autoref{tbl:ex3}, even with one thread there is a small speed-up because the master thread does reading from a file while the single worker thread processes images. Because this is done concurrently there is a slight speed-up. 

We can also see that the maximum achievable speed-up most likely lies at about 4.4 since that value is approached with a large number of threads. The speed-up is most likely limited by the fact that we lock a mutex whenever the something is put on or taken off the queue. We also have a mutex that regulates access to stdout so there is another opportunity for threads to wait for each other. It seems that this strategy doesn't seem really effective because of all this locking. It might be possible to speed the program up a little bit more if adding items to the queue and removing them would use different mutexes.

\begin{table}
	\centering
	\caption{Run times and speed-up for the master/worker model.}
	\label{tbl:ex3}
	\begin{tabular}{r|r|r}
		Number of threads & Run time & Speed-up \\ \hline
		Sequential & 72.13 &  \\
		 1 & 66.76 & 1.08 \\
		 2 & 34.61 & 2.08 \\
		 4 & 20.75 & 3.48 \\
		 8 & 16.69 & 4.32 \\
		12 & 16.51 & 4.37 \\
	\end{tabular}
\end{table}

\clearpage
\appendix
\section{Full program code}
\subsection{Program code exercise 1}
%\lstinputlisting[label={code:prime1}, caption={Code for prime search by static domain decomposition}]{prime/prime.c}

\subsection{Code for exercise 2}
\lstinputlisting[label={code:ocr-ex2}, caption={Main code for exercise 2}, firstline=518]{ocr-ex2.c}

\subsection{Code for exercise 3}
\lstinputlisting[label={code:ocr-ex2}, caption={Main code for exercise 3}, firstline=547]{ocr-ex3.c}

\subsection{Program code for auxilary files}\label{sec:aux}
\lstinputlisting[label={code:queue.h}, caption={Helper code to manage queues}]{queue.h}
\lstinputlisting[label={code:queue.c}, caption={Helper code to manage queues}]{queue.c}
\lstinputlisting[label={code:stringbuffer.h}, caption={Helper code to manage queues}]{stringbuffer.h}
\lstinputlisting[label={code:stringbuffer.c}, caption={Helper code to manage queues}]{stringbuffer.c}

\end{document}